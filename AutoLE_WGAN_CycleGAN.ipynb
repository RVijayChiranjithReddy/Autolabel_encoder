{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoLE_WGAN_CycleGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVijayChiranjithReddy/Autolabel_encoder/blob/main/AutoLE_WGAN_CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ3DsF2gTT36",
        "outputId": "4fe0f73d-6917-4139-dd0b-3190dc8907f3"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import *\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.applications import *\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob\n",
        "from random import randint, shuffle\n",
        "%matplotlib inline\n",
        "K.set_learning_phase(1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiC1CpTdTb-4",
        "outputId": "d9e26cc5-45e3-4875-899d-1ef165188849"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CUE6JV0Tew2",
        "outputId": "874b70a4-9f74-46c2-af6e-cabebe1276e5"
      },
      "source": [
        "import pandas\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "df = pandas.read_csv('/content/styles.csv')\n",
        "df.fillna('DK', inplace = True) \n",
        "data = {}\n",
        "for i in range(44446):\n",
        "  tags = [str(x) for x in df.loc[i].values[1:9] if type(x) is str]\n",
        "  #desc = df.loc[i].values[9]\n",
        "  #if type(desc) is not float:\n",
        "    #for de in desc.split():\n",
        "     #if de.isalpha() and de not in tags:\n",
        "        #tags.append(de)\n",
        "  data[str(df.loc[i].values[0])] = ':'.join(tags)\n",
        "vocab = []\n",
        "for k,v in data.items():\n",
        "  temp = list(set(v.split(':')))\n",
        "  vocab = vocab + temp\n",
        "  vocab = list(set(vocab))\n",
        "print(len(vocab))\n",
        "#from tensorflow.keras.preprocessing.text import one_hot\n",
        "#for k,d in data.items():\n",
        "  #data_encoded[k] = one_hot(' '.join(d),len(vocab))\n",
        "tokenizer = Tokenizer(num_words=len(vocab))\n",
        "\n",
        "# This builds the word index\n",
        "tokenizer.fit_on_texts(data.values())\n",
        "\n",
        "\n",
        "# This turns strings into lists of integer indices.\n",
        "train_sequences = tokenizer.texts_to_sequences(data.values())\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "240\n",
            "{'casual': 1, 'men': 2, 'apparel': 3, 'summer': 4, 'women': 5, 'topwear': 6, 'shoes': 7, 'accessories': 8, 'fall': 9, 'black': 10, 'footwear': 11, 'winter': 12, 'tshirts': 13, 'blue': 14, 'sports': 15, 'white': 16, 'watches': 17, 'brown': 18, 'shirts': 19, 'ethnic': 20, 'bags': 21, 'formal': 22, 'spring': 23, 'grey': 24, 'bottomwear': 25, 'care': 26, 'red': 27, 'personal': 28, 'unisex': 29, 'green': 30, 'innerwear': 31, 'wallets': 32, 'pink': 33, 'kurtas': 34, 'flip': 35, 'flops': 36, 'navy': 37, 'tops': 38, 'handbags': 39, 'purple': 40, 'belts': 41, 'and': 42, 'socks': 43, 'heels': 44, 'jewellery': 45, 'silver': 46, 'eyewear': 47, 'sunglasses': 48, 'fragrance': 49, 'sandals': 50, 'sandal': 51, 'briefs': 52, 'boys': 53, 'yellow': 54, 'beige': 55, 'backpacks': 56, 'girls': 57, 'body': 58, 'gold': 59, 'perfume': 60, 'mist': 61, 'jeans': 62, 'shorts': 63, 'maroon': 64, 'trousers': 65, 'orange': 66, 'lips': 67, 'ties': 68, 'flats': 69, 'dress': 70, 'bra': 71, 'loungewear': 72, 'nightwear': 73, 'dresses': 74, 'saree': 75, 'sarees': 76, 'earrings': 77, 'olive': 78, 'cream': 79, 'multi': 80, 'pants': 81, 'dk': 82, 'deodorant': 83, 'set': 84, 'nail': 85, 'nails': 86, 'polish': 87, 'skin': 88, 'lipstick': 89, 'steel': 90, 'makeup': 91, 'track': 92, 'free': 93, 'headwear': 94, 'clutches': 95, 'sweatshirts': 96, 'caps': 97, 'sweaters': 98, 'jackets': 99, 'vests': 100, 'scarves': 101, 'kurtis': 102, 'tunics': 103, 'charcoal': 104, 'bag': 105, 'cufflinks': 106, 'lip': 107, 'peach': 108, 'gifts': 109, 'nightdress': 110, 'off': 111, 'stoles': 112, 'leggings': 113, 'pendant': 114, 'capris': 115, 'gift': 116, 'lavender': 117, 'necklace': 118, 'chains': 119, 'melange': 120, 'gloss': 121, 'suits': 122, 'night': 123, 'trunk': 124, 'khaki': 125, 'accessory': 126, 'magenta': 127, 'skirts': 128, 'dupatta': 129, 'teal': 130, 'ring': 131, 'tan': 132, 'items': 133, 'kajal': 134, 'eyeliner': 135, 'lounge': 136, 'mustard': 137, 'face': 138, 'bronze': 139, 'kurta': 140, 'sets': 141, 'duffel': 142, 'copper': 143, 'bangle': 144, 'laptop': 145, 'mufflers': 146, 'foundation': 147, 'primer': 148, 'turquoise': 149, 'smart': 150, 'bracelet': 151, 'rust': 152, 'pouch': 153, 'moisturisers': 154, 'highlighter': 155, 'blush': 156, 'boxers': 157, 'compact': 158, 'shoe': 159, 'liner': 160, 'mobile': 161, 'burgundy': 162, 'messenger': 163, 'metallic': 164, 'eyes': 165, 'travel': 166, 'eyeshadow': 167, 'suspenders': 168, 'gloves': 169, 'camisoles': 170, 'salwar': 171, 'hair': 172, 'patiala': 173, 'jeggings': 174, 'bath': 175, 'stockings': 176, 'coffee': 177, 'churidar': 178, 'wash': 179, 'tracksuits': 180, 'mauve': 181, 'party': 182, 'cleanser': 183, 'rose': 184, 'sporting': 185, 'goods': 186, 'sunscreen': 187, 'robe': 188, 'nude': 189, 'sea': 190, 'equipment': 191, 'rain': 192, 'colour': 193, 'jacket': 194, 'water': 195, 'bottle': 196, 'swimwear': 197, 'waist': 198, 'baby': 199, 'dolls': 200, 'jumpsuit': 201, 'mushroom': 202, 'waistcoat': 203, 'basketballs': 204, 'mascara': 205, 'mask': 206, 'peel': 207, 'rompers': 208, 'booties': 209, 'umbrellas': 210, 'taupe': 211, 'wristbands': 212, 'concealer': 213, 'rucksacks': 214, 'tights': 215, 'shapewear': 216, 'blazers': 217, 'beauty': 218, 'footballs': 219, 'clothing': 220, 'headband': 221, 'shrug': 222, 'lime': 223, 'eye': 224, 'essentials': 225, 'scrub': 226, 'lotion': 227, 'perfumes': 228, 'exfoliator': 229, 'nehru': 230, 'toner': 231, 'fluorescent': 232, 'lehenga': 233, 'choli': 234, 'remover': 235, 'plumper': 236, 'trolley': 237, 'tablet': 238, 'sleeve': 239, 'home': 240, 'hat': 241, 'key': 242, 'chain': 243, 'serum': 244, 'gel': 245, 'laces': 246, 'furnishing': 247, 'cushion': 248, 'covers': 249, 'mens': 250, 'grooming': 251, 'kit': 252, 'vouchers': 253, 'ipad': 254}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqMJnykpTfax",
        "outputId": "aec18e63-406c-4813-8cc1-fd91abe5806a"
      },
      "source": [
        "da = {}\n",
        "ds = {}\n",
        "i=0\n",
        "a = tokenizer.sequences_to_matrix(train_sequences,mode='binary')\n",
        "print(a.shape)\n",
        "for k,v in data.items():\n",
        "  da[str(k)] = train_sequences[i]\n",
        "  i=i+1\n",
        "i=0\n",
        "for k,v in data.items():\n",
        "  ds[k] = np.array(a[i,:])\n",
        "  i=i+1\n",
        "print(da['10000'])\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy\n",
        "max_length = 13\n",
        "d_enc_padded = {}\n",
        "for k,d in da.items():\n",
        " pad = pad_sequences([d],maxlen=max_length,padding='post')\n",
        " d_enc_padded[str(k)] = numpy.array(pad[0])\n",
        "print(d_enc_padded['10000'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44446, 240)\n",
            "[5, 3, 25, 128, 16, 4, 1]\n",
            "[  5   3  25 128  16   4   1   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDVqVI1ZTiuk"
      },
      "source": [
        "def read_image(fn):\n",
        "  im = cv2.imread(fn)\n",
        "  im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
        "  im = cv2.resize(im, (128,128), interpolation=cv2.INTER_CUBIC)\n",
        "  im = np.array(im)/255*2-1\n",
        "  return im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20pwI_fOTkr1"
      },
      "source": [
        "traini = glob.glob(r'/content/drive/MyDrive/images/*')\n",
        "print(len(traini))\n",
        "def minibatch(data, batchsize):\n",
        "    length = len(data)\n",
        "    epoch = i = 0\n",
        "    tmpsize = None    \n",
        "    while True:\n",
        "        size = tmpsize if tmpsize else batchsize\n",
        "        if i+size > length:\n",
        "            shuffle(data)\n",
        "            i = 0\n",
        "            epoch+=1        \n",
        "        rtn = [read_image(data[j]) for j in range(i,i+size)]\n",
        "        ltn=[]\n",
        "        se = []\n",
        "        for j in range(i,i+size):\n",
        "          if '(' in data[j].split('/')[-1].split('.')[0]:\n",
        "            ltn.append(d_enc_padded[data[j].split('/')[-1].split('.')[0].split(' ')[0]])\n",
        "          else:\n",
        "            ltn.append(d_enc_padded[data[j].split('/')[-1].split('.')[0]])\n",
        "        i+=size\n",
        "        tmpsize = yield epoch, np.float32(rtn), np.array(ltn)/239\n",
        "\n",
        "def minibatchAB(dataA, batchsize):\n",
        "    batchA = minibatch(dataA, batchsize)\n",
        "    tmpsize = None    \n",
        "    while True:        \n",
        "        ep1, A,B = batchA.send(tmpsize)\n",
        "        tmpsize = yield ep1, A,B\n",
        "train_batch = minibatchAB(traini, 64)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz7Ecbqw9DzN"
      },
      "source": [
        "class ClipConstraint(tf.keras.constraints.Constraint):\n",
        "  def __init__(self, clip_value):\n",
        "    self.clip_value = clip_value\n",
        "  def __call__(self, weights):\n",
        "    return backend.clip(weights, -self.clip_value, self.clip_value)\n",
        "  def get_config(self):\n",
        "    return {'clip_value': self.clip_value}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLykj6zJ-CwL"
      },
      "source": [
        "const = ClipConstraint(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcatxM4UTmXW"
      },
      "source": [
        "class CycleGAN():\n",
        "  def __init__(self,train_batch,const):\n",
        "    self.img_rows = 128 \n",
        "    self.img_cols = 128 \n",
        "    self.channels = 3 \n",
        "    self.traindata = train_batch\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "    self.label_shape = (13,)\n",
        "    self.lambda_cycle = 10.0 \n",
        "    optimizer = RMSprop(learning_rate =0.00005)\n",
        "    self.const = const\n",
        "    self.g_AB = self.build_label_generator() \n",
        "    self.g_BA = self.build_img_generator()\n",
        "    A = Input(shape=self.img_shape) \n",
        "    B = Input(shape=self.label_shape) \n",
        "    fake_B = self.g_AB(A) \n",
        "    fake_A = self.g_BA(B)\n",
        "    reconstr_A = self.g_BA(fake_B) \n",
        "    reconstr_B = self.g_AB(fake_A)\n",
        "    self.d_A = self.build_img_label_discriminator() \n",
        "    self.d_B = self.build_img_label_discriminator() \n",
        "    self.d_A.compile(loss='mse',optimizer=optimizer) \n",
        "    self.d_B.compile(loss='mse',optimizer=optimizer)  \n",
        "    self.d_A.trainable = False \n",
        "    self.d_B.trainable = False\n",
        "    valid_A = self.d_A([fake_A,B]) \n",
        "    valid_B = self.d_B([A,fake_B])\n",
        "    self.combined = Model(inputs=[A,B],outputs=[valid_A, valid_B,reconstr_A, reconstr_B]) \n",
        "    self.combined.compile(loss=[self.wa_loss,self.wa_loss,tf.keras.losses.kl_divergence,tf.keras.losses.kl_divergence],loss_weights=[1, 1,self.lambda_cycle, self.lambda_cycle],optimizer=optimizer)\n",
        "  def wa_loss(self,y_true, y_pred):\n",
        "    return K.mean(y_true * y_pred)\n",
        "  def build_img_generator(self):\n",
        "    d0 = Input(shape=self.label_shape)\n",
        "    d1 = Dense(128,activation = 'relu')(d0)\n",
        "    d2 = tf.keras.layers.Reshape((1,1,128))(d1)\n",
        "    d3 = Conv2DTranspose(128,kernel_size = 3,strides = 2,padding = 'same')(d2)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(128,kernel_size = 3,strides = 1,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(128,kernel_size = 3,strides = 1,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(64,kernel_size = 3,strides = 2,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(64,kernel_size = 3,strides = 1,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(64,kernel_size = 3,strides = 2,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(64,kernel_size = 3,strides = 1,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(32,kernel_size = 3,strides = 2,padding = 'same')(d3)\n",
        "    d3 = Conv2DTranspose(32,kernel_size = 3,strides = 1,padding = 'same')(d3)\n",
        "    d3 = Conv2DTranspose(32,kernel_size = 3,strides = 2,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(16,kernel_size = 3,strides = 2,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(16,kernel_size = 3,strides = 2,padding = 'same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = LeakyReLU(alpha=0.2)(d3)\n",
        "    d3 = Conv2DTranspose(8,kernel_size = 3,strides = 1,padding = 'same')(d3)\n",
        "    output_img = Conv2D(3,kernel_size = 3,strides = 1,padding = 'same',activation='tanh')(d3)\n",
        "    return Model(d0, output_img) \n",
        "  def build_label_generator(self):\n",
        "    d0 = Input(shape=self.img_shape)\n",
        "    d1 = Conv2D(32,kernel_size = 3,strides = 1,padding = 'same')(d0)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(32,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(64,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(64,kernel_size = 3,strides = 1,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(64,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(128,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(128,kernel_size = 3,strides = 1,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(128,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(256,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(512,kernel_size = 3,strides = 2,padding = 'same')(d1)\n",
        "    d2 = Flatten()(d1)\n",
        "    d2 = Dense(512,activation='relu')(d2)\n",
        "    d2 = Dense(256,activation='relu')(d2)\n",
        "    d2 = Dense(128,activation='relu')(d2)\n",
        "    output_label = Dense(13,activation='relu')(d2)\n",
        "    return Model(d0, output_label)\n",
        "  def build_img_label_discriminator(self):\n",
        "    x1 = Input(shape=self.img_shape)\n",
        "    x2 = Input(shape=self.label_shape)\n",
        "    d1 = Conv2D(32,kernel_size = 3,strides = 4,kernel_constraint=self.const,padding = 'same',tf.keras.initializers.HeNormal())(x1)\n",
        "    d1 = Conv2D(64,kernel_size = 3,strides = 4,kernel_constraint=self.const,padding = 'same',tf.keras.initializers.HeNormal())(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(128,kernel_size = 3,strides = 4,kernel_constraint=self.const,padding = 'same',tf.keras.initializers.HeNormal())(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d1 = Conv2D(512,kernel_size = 3,strides = 2,kernel_constraint=self.const,padding = 'same',tf.keras.initializers.HeNormal())(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d2 = Flatten()(d1)\n",
        "    d2 = Dense(13)(d2)\n",
        "    con = concatenate([d2,x2],axis=-1)\n",
        "    d3 = Dense(128,activation='relu',tf.keras.initializers.HeNormal())(con)\n",
        "    d3 = Dense(64,activation='relu')(d3)\n",
        "    validity = Dense(1)(d3)\n",
        "    return Model(inputs = [x1,x2], outputs = [validity])\n",
        "  def train(self, epochs, batch_size=64, sample_interval=50):\n",
        "    valid = np.ones((batch_size,1))*(-1)\n",
        "    fake = np.ones((batch_size,1))\n",
        "    for epoch in range(epochs):\n",
        "      for i in range(3):\n",
        "        ep, A,B= next(self.traindata)\n",
        "        fake_B = self.g_AB.predict(A) \n",
        "        fake_A = self.g_BA.predict(B)\n",
        "        dA_loss_real = self.d_A.train_on_batch([A,B], valid) \n",
        "        dA_loss_fake = self.d_A.train_on_batch([fake_A,B], fake)\n",
        "        dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "        dB_loss_real = self.d_B.train_on_batch([A,B], valid)\n",
        "        dB_loss_fake = self.d_B.train_on_batch([A,fake_B], fake)\n",
        "        dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "      d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "      ep, A,B= next(self.traindata)\n",
        "      g_loss = self.combined.train_on_batch([A,B],[valid, valid,A,B])\n",
        "      if epoch % sample_interval == 0: \n",
        "        print(\"%d [D loss : %f ] [G loss : %f]\"%(epoch,np.mean(d_loss),np.mean(g_loss)))\n",
        "        gan.combined.save('/content/drive/MyDrive/cwgan.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRsqwq-_Tpin"
      },
      "source": [
        "gan = CycleGAN(train_batch,const)\n",
        "gan.train(epochs=3000, batch_size=64, sample_interval=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbJNS-v9TqHt"
      },
      "source": [
        "A = read_image('/content/drive/MyDrive/images/10000.jpg')\n",
        "A = np.expand_dims(A,axis=0)\n",
        "res = gan.g_AB.predict(A)\n",
        "print(d_enc_padded['10000'])\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2n3S3pERbIV"
      },
      "source": [
        "gan.combined.save('/content/drive/MyDrive/cwgan.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}